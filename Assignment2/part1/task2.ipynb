{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and Normalizing CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load CIFAR dataset with flattening in the transform\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     transforms.Lambda(lambda x: torch.flatten(x))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement MLP PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_train_mlp import accuracy, train\n",
    "from task2_train_mlp import accuracy as mlp_pytorch_accuracy\n",
    "from task2_train_mlp import train as mlp_pytorch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def prepare_dataset(loader):\n",
    "    \"\"\" Concatenate all batches into single numpy arrays. \"\"\"\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    for data, labels in loader:\n",
    "        all_data.append(data.numpy())  # Convert tensors to numpy arrays\n",
    "        all_labels.append(labels.numpy())\n",
    "    \n",
    "    # Concatenate all data and labels along the first dimension (batch dimension)\n",
    "    all_data = np.concatenate(all_data, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    \n",
    "    return all_data, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameter configuration for MLP\n",
    "dnn_hidden_units = '512,256,128'\n",
    "learning_rate = 1e-2\n",
    "max_steps = 1500\n",
    "eval_freq = 10\n",
    "mode = 'stochastic'\n",
    "batch_size = 0\n",
    "weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_dataset(trainloader)\n",
    "X_test, y_test = prepare_dataset(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images since DataLoader output will be batches of 3x32x32 tensors\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Test Loss: 2.3043, Accuracy: 9.43%\n",
      "Step: 10, Test Loss: 2.3030, Accuracy: 9.92%\n",
      "Step: 20, Test Loss: 2.3018, Accuracy: 10.29%\n",
      "Step: 30, Test Loss: 2.3005, Accuracy: 10.71%\n",
      "Step: 40, Test Loss: 2.2992, Accuracy: 11.26%\n",
      "Step: 50, Test Loss: 2.2980, Accuracy: 11.81%\n",
      "Step: 60, Test Loss: 2.2967, Accuracy: 12.45%\n",
      "Step: 70, Test Loss: 2.2954, Accuracy: 13.07%\n",
      "Step: 80, Test Loss: 2.2941, Accuracy: 13.82%\n",
      "Step: 90, Test Loss: 2.2928, Accuracy: 14.44%\n",
      "Step: 100, Test Loss: 2.2915, Accuracy: 15.00%\n",
      "Step: 110, Test Loss: 2.2901, Accuracy: 15.52%\n",
      "Step: 120, Test Loss: 2.2888, Accuracy: 16.12%\n",
      "Step: 130, Test Loss: 2.2874, Accuracy: 16.63%\n",
      "Step: 140, Test Loss: 2.2860, Accuracy: 17.12%\n",
      "Step: 150, Test Loss: 2.2845, Accuracy: 17.58%\n",
      "Step: 160, Test Loss: 2.2830, Accuracy: 18.16%\n",
      "Step: 170, Test Loss: 2.2815, Accuracy: 18.54%\n",
      "Step: 180, Test Loss: 2.2799, Accuracy: 18.90%\n",
      "Step: 190, Test Loss: 2.2782, Accuracy: 19.34%\n",
      "Step: 200, Test Loss: 2.2765, Accuracy: 19.70%\n",
      "Step: 210, Test Loss: 2.2747, Accuracy: 20.04%\n",
      "Step: 220, Test Loss: 2.2728, Accuracy: 20.41%\n",
      "Step: 230, Test Loss: 2.2709, Accuracy: 20.53%\n",
      "Step: 240, Test Loss: 2.2688, Accuracy: 20.79%\n",
      "Step: 250, Test Loss: 2.2667, Accuracy: 20.78%\n",
      "Step: 260, Test Loss: 2.2644, Accuracy: 20.71%\n",
      "Step: 270, Test Loss: 2.2621, Accuracy: 20.85%\n",
      "Step: 280, Test Loss: 2.2596, Accuracy: 21.06%\n",
      "Step: 290, Test Loss: 2.2569, Accuracy: 21.22%\n",
      "Step: 300, Test Loss: 2.2542, Accuracy: 21.54%\n",
      "Step: 310, Test Loss: 2.2513, Accuracy: 21.69%\n",
      "Step: 320, Test Loss: 2.2482, Accuracy: 21.98%\n",
      "Step: 330, Test Loss: 2.2450, Accuracy: 22.24%\n",
      "Step: 340, Test Loss: 2.2416, Accuracy: 22.58%\n",
      "Step: 350, Test Loss: 2.2380, Accuracy: 22.87%\n",
      "Step: 360, Test Loss: 2.2343, Accuracy: 22.97%\n",
      "Step: 370, Test Loss: 2.2304, Accuracy: 22.99%\n",
      "Step: 380, Test Loss: 2.2262, Accuracy: 22.97%\n",
      "Step: 390, Test Loss: 2.2219, Accuracy: 22.91%\n",
      "Step: 400, Test Loss: 2.2174, Accuracy: 23.01%\n",
      "Step: 410, Test Loss: 2.2127, Accuracy: 22.74%\n",
      "Step: 420, Test Loss: 2.2079, Accuracy: 22.59%\n",
      "Step: 430, Test Loss: 2.2029, Accuracy: 22.59%\n",
      "Step: 440, Test Loss: 2.1977, Accuracy: 22.79%\n",
      "Step: 450, Test Loss: 2.1924, Accuracy: 22.77%\n",
      "Step: 460, Test Loss: 2.1869, Accuracy: 22.79%\n",
      "Step: 470, Test Loss: 2.1814, Accuracy: 22.88%\n",
      "Step: 480, Test Loss: 2.1757, Accuracy: 22.94%\n",
      "Step: 490, Test Loss: 2.1700, Accuracy: 23.17%\n",
      "Step: 500, Test Loss: 2.1642, Accuracy: 23.27%\n",
      "Step: 510, Test Loss: 2.1583, Accuracy: 23.65%\n",
      "Step: 520, Test Loss: 2.1524, Accuracy: 23.88%\n",
      "Step: 530, Test Loss: 2.1465, Accuracy: 24.17%\n",
      "Step: 540, Test Loss: 2.1405, Accuracy: 24.25%\n",
      "Step: 550, Test Loss: 2.1346, Accuracy: 24.43%\n",
      "Step: 560, Test Loss: 2.1286, Accuracy: 24.66%\n",
      "Step: 570, Test Loss: 2.1227, Accuracy: 24.87%\n",
      "Step: 580, Test Loss: 2.1168, Accuracy: 25.05%\n",
      "Step: 590, Test Loss: 2.1110, Accuracy: 25.17%\n",
      "Step: 600, Test Loss: 2.1051, Accuracy: 25.29%\n",
      "Step: 610, Test Loss: 2.0994, Accuracy: 25.42%\n",
      "Step: 620, Test Loss: 2.0937, Accuracy: 25.43%\n",
      "Step: 630, Test Loss: 2.0880, Accuracy: 25.68%\n",
      "Step: 640, Test Loss: 2.0824, Accuracy: 25.87%\n",
      "Step: 650, Test Loss: 2.0769, Accuracy: 25.98%\n",
      "Step: 660, Test Loss: 2.0714, Accuracy: 26.19%\n",
      "Step: 670, Test Loss: 2.0660, Accuracy: 26.34%\n",
      "Step: 680, Test Loss: 2.0606, Accuracy: 26.49%\n",
      "Step: 690, Test Loss: 2.0554, Accuracy: 26.55%\n",
      "Step: 700, Test Loss: 2.0501, Accuracy: 26.67%\n",
      "Step: 710, Test Loss: 2.0450, Accuracy: 26.94%\n",
      "Step: 720, Test Loss: 2.0399, Accuracy: 27.01%\n",
      "Step: 730, Test Loss: 2.0349, Accuracy: 27.16%\n",
      "Step: 740, Test Loss: 2.0300, Accuracy: 27.41%\n",
      "Step: 750, Test Loss: 2.0252, Accuracy: 27.50%\n",
      "Step: 760, Test Loss: 2.0204, Accuracy: 27.63%\n",
      "Step: 770, Test Loss: 2.0157, Accuracy: 27.72%\n",
      "Step: 780, Test Loss: 2.0111, Accuracy: 27.85%\n",
      "Step: 790, Test Loss: 2.0066, Accuracy: 28.08%\n",
      "Step: 800, Test Loss: 2.0021, Accuracy: 28.25%\n",
      "Step: 810, Test Loss: 1.9978, Accuracy: 28.45%\n",
      "Step: 820, Test Loss: 1.9935, Accuracy: 28.57%\n",
      "Step: 830, Test Loss: 1.9893, Accuracy: 28.63%\n",
      "Step: 840, Test Loss: 1.9852, Accuracy: 28.67%\n",
      "Step: 850, Test Loss: 1.9812, Accuracy: 28.80%\n",
      "Step: 860, Test Loss: 1.9772, Accuracy: 29.03%\n",
      "Step: 870, Test Loss: 1.9733, Accuracy: 29.15%\n",
      "Step: 880, Test Loss: 1.9695, Accuracy: 29.31%\n",
      "Step: 890, Test Loss: 1.9658, Accuracy: 29.52%\n",
      "Step: 900, Test Loss: 1.9621, Accuracy: 29.68%\n",
      "Step: 910, Test Loss: 1.9585, Accuracy: 29.80%\n",
      "Step: 920, Test Loss: 1.9550, Accuracy: 29.95%\n",
      "Step: 930, Test Loss: 1.9515, Accuracy: 30.09%\n",
      "Step: 940, Test Loss: 1.9481, Accuracy: 30.25%\n",
      "Step: 950, Test Loss: 1.9447, Accuracy: 30.38%\n",
      "Step: 960, Test Loss: 1.9414, Accuracy: 30.43%\n",
      "Step: 970, Test Loss: 1.9381, Accuracy: 30.60%\n",
      "Step: 980, Test Loss: 1.9349, Accuracy: 30.75%\n",
      "Step: 990, Test Loss: 1.9318, Accuracy: 30.93%\n",
      "Step: 1000, Test Loss: 1.9286, Accuracy: 30.91%\n",
      "Step: 1010, Test Loss: 1.9256, Accuracy: 30.92%\n",
      "Step: 1020, Test Loss: 1.9225, Accuracy: 31.05%\n",
      "Step: 1030, Test Loss: 1.9195, Accuracy: 31.11%\n",
      "Step: 1040, Test Loss: 1.9165, Accuracy: 31.28%\n",
      "Step: 1050, Test Loss: 1.9136, Accuracy: 31.33%\n",
      "Step: 1060, Test Loss: 1.9107, Accuracy: 31.41%\n",
      "Step: 1070, Test Loss: 1.9078, Accuracy: 31.51%\n",
      "Step: 1080, Test Loss: 1.9050, Accuracy: 31.59%\n",
      "Step: 1090, Test Loss: 1.9021, Accuracy: 31.72%\n",
      "Step: 1100, Test Loss: 1.8993, Accuracy: 31.88%\n",
      "Step: 1110, Test Loss: 1.8966, Accuracy: 32.03%\n",
      "Step: 1120, Test Loss: 1.8938, Accuracy: 32.14%\n",
      "Step: 1130, Test Loss: 1.8911, Accuracy: 32.21%\n",
      "Step: 1140, Test Loss: 1.8884, Accuracy: 32.29%\n",
      "Step: 1150, Test Loss: 1.8857, Accuracy: 32.37%\n",
      "Step: 1160, Test Loss: 1.8830, Accuracy: 32.54%\n",
      "Step: 1170, Test Loss: 1.8804, Accuracy: 32.54%\n",
      "Step: 1180, Test Loss: 1.8778, Accuracy: 32.65%\n",
      "Step: 1190, Test Loss: 1.8752, Accuracy: 32.78%\n",
      "Step: 1200, Test Loss: 1.8726, Accuracy: 32.95%\n",
      "Step: 1210, Test Loss: 1.8700, Accuracy: 33.09%\n",
      "Step: 1220, Test Loss: 1.8674, Accuracy: 33.23%\n",
      "Step: 1230, Test Loss: 1.8649, Accuracy: 33.39%\n",
      "Step: 1240, Test Loss: 1.8624, Accuracy: 33.45%\n",
      "Step: 1250, Test Loss: 1.8599, Accuracy: 33.60%\n",
      "Step: 1260, Test Loss: 1.8574, Accuracy: 33.70%\n",
      "Step: 1270, Test Loss: 1.8549, Accuracy: 33.85%\n",
      "Step: 1280, Test Loss: 1.8524, Accuracy: 34.04%\n",
      "Step: 1290, Test Loss: 1.8499, Accuracy: 34.23%\n",
      "Step: 1300, Test Loss: 1.8475, Accuracy: 34.39%\n",
      "Step: 1310, Test Loss: 1.8451, Accuracy: 34.53%\n",
      "Step: 1320, Test Loss: 1.8427, Accuracy: 34.66%\n",
      "Step: 1330, Test Loss: 1.8403, Accuracy: 34.79%\n",
      "Step: 1340, Test Loss: 1.8379, Accuracy: 35.03%\n",
      "Step: 1350, Test Loss: 1.8355, Accuracy: 35.13%\n",
      "Step: 1360, Test Loss: 1.8331, Accuracy: 35.15%\n",
      "Step: 1370, Test Loss: 1.8308, Accuracy: 35.24%\n",
      "Step: 1380, Test Loss: 1.8284, Accuracy: 35.38%\n",
      "Step: 1390, Test Loss: 1.8261, Accuracy: 35.51%\n",
      "Step: 1400, Test Loss: 1.8238, Accuracy: 35.59%\n",
      "Step: 1410, Test Loss: 1.8215, Accuracy: 35.69%\n",
      "Step: 1420, Test Loss: 1.8192, Accuracy: 35.76%\n",
      "Step: 1430, Test Loss: 1.8169, Accuracy: 35.90%\n",
      "Step: 1440, Test Loss: 1.8147, Accuracy: 35.93%\n",
      "Step: 1450, Test Loss: 1.8124, Accuracy: 35.98%\n",
      "Step: 1460, Test Loss: 1.8102, Accuracy: 36.00%\n",
      "Step: 1470, Test Loss: 1.8079, Accuracy: 36.06%\n",
      "Step: 1480, Test Loss: 1.8057, Accuracy: 36.12%\n",
      "Step: 1490, Test Loss: 1.8035, Accuracy: 36.18%\n",
      "Step: 1499, Test Loss: 1.8015, Accuracy: 36.25%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "loss, acc = mlp_pytorch_train(X_train, y_train, X_test, y_test, dnn_hidden_units, learning_rate, max_steps, eval_freq, weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting the loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "# Generate a range that matches the length of the losses array\n",
    "steps = range(0, len(loss) * eval_freq, eval_freq)\n",
    "plt.plot(steps, loss, label='Test Loss')\n",
    "plt.title('Loss over steps')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "# Use the same steps range as for losses\n",
    "plt.plot(steps, acc, label='Test Accuracy')\n",
    "plt.title('Accuracy over steps')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
